# Yantra Codex: Complete Implementation Plan

**Date:** November 26, 2025 (Updated)  
**Status:** ğŸš€ Ready to Implement  
**Vision:** GNN + Tree-sitter â†’ Yantra Cloud Codex (Universal Collective Intelligence)

---

## Executive Summary

**Key Decisions (Nov 26 Update):**
1. âœ… **Start with 1024 dims** (not 256) - Better accuracy from Day 1
2. âœ… **Yantra Cloud Codex** - Universal learning (not per-user)
3. âœ… **Coding is THE specialization** - Like AlphaGo for code
4. âœ… **Multi-language from Day 1** - GNN logic + Tree-sitter syntax

Yantra Codex is a universal coding AI that learns from ALL users and improves continuously:

### Phase 1: Local GNN + Collective Learning
- **Architecture:** GNN (1024 dims) + Tree-sitter for multi-language code generation
- **Bootstrap:** Train on curated CodeContests dataset (6,508 examples)
- **On-the-go Learning:** Every user's validated code becomes training data
- **LLM Fallback:** When GNN confidence < threshold, use LLM and learn from it
- **Result:** Universal coding AI that improves from collective intelligence
- **Privacy:** Only anonymous logic patterns shared (not code)

### Phase 2: Yantra Cloud Codex (Universal Intelligence)
- **Central GNN:** Aggregates anonymous patterns from ALL users globally
- **Collective Learning:** Everyone's validated code improves everyone's model
- **Distribution:** Push improved GNN models to all users (weekly/monthly updates)
- **Privacy:** Only anonymous logic patterns sent to cloud (NOT code)
- **Network Effects:** More users â†’ More patterns â†’ Better model â†’ Attracts more users
- **Result:** Free/low-cost coding AI that rivals GPT-4 for code generation

---

## Part 1: Yantra Codex Architecture (Clarified Nov 26, 2025)

### Critical Decisions

**1. Start with 1024 Dimensions (Not 256)**
- Cost difference: Negligible (3GB storage, 10ms latency)
- Benefit: 15-20% higher accuracy from Day 1 (60% vs 40%)
- Better user retention (acceptable UX vs frustrating UX)

**2. Yantra Cloud Codex (Universal Learning)**
- Single global model learning from ALL users
- Network effects: More users = Better model for everyone
- Privacy-preserved: Only anonymous logic patterns shared (NOT code)

**3. Coding Specialization**
- Focuses ONLY on code generation (all languages)
- Like AlphaGo specialized in Go, Yantra specializes in coding
- Learns universal coding patterns that work across languages

**4. Multi-Language via Logic + Syntax Separation**
- GNN learns universal logic patterns (language-independent)
- Tree-sitter generates language-specific syntax
- Transfer learning: Learn once in Python, works in JavaScript/Rust/Go

### 1.1 How GNN Generates Code

**Critical Understanding:**
- âŒ GNN **CANNOT** generate code text directly (outputs numbers only)
- âœ… GNN **predicts logic patterns** (what steps to take)
- âœ… Tree-sitter **generates actual code** from logic patterns

**Flow:**
```
Problem: "Validate email and save to database"
    â†“
Extract Features: 978-dimensional vector
    â†“
GNN Predicts Logic Pattern (1024-dimensional embedding):
    Step 1: null_check
    Step 2: regex_validation  
    Step 3: duplicate_check (db query)
    Step 4: db_insert
    Step 5: error_handling
    â†“
Decode to AST Structure:
    - if_statement (null check)
    - if_statement (regex check)
    - if_statement (duplicate check)
    - database_operation (insert)
    - return success
    â†“
Tree-sitter Generates Code (language-specific):
    Python:     if not email: return False...
    JavaScript: if (!email) return false;...
    Rust:       if email.is_empty() { return Ok(false); }...
```

### 1.2 Model Architecture (1024 dims)

```python
class YantraCodex:
    """1024-dim GraphSAGE for multi-language code generation"""
    
    def __init__(self):
        # Encoder: 978 â†’ 1536 â†’ 1280 â†’ 1024
        self.encoder = GraphSAGE(
            input_dim=978,
            hidden_dims=[1536, 1280],
            output_dim=1024,
            dropout=0.2
        )
        
        # Prediction heads
        self.logic_pattern = nn.Linear(1024, 1024)
        self.confidence = nn.Linear(1024, 1)
        self.complexity = nn.Linear(1024, 5)
        
        # Language-specific generators  
        self.generators = {
            'python': PythonTreeSitter(),
            'javascript': JavaScriptTreeSitter(),
            'typescript': TypeScriptTreeSitter(),
            'rust': RustTreeSitter(),
            'go': GoTreeSitter(),
        }
    
    def generate(self, problem: str, language: str):
        # Universal logic prediction
        features = extract_features(problem)      # 978 dims
        logic_embedding = self.encoder(features)  # 1024 dims
        confidence = self.confidence(logic_embedding)
        
        # Decode to AST structure
        ast_structure = decode_logic(logic_embedding)
        
        # Generate code in target language
        generator = self.generators[language]
        code = generator.generate(ast_structure)
        
        return code, confidence
```

**Specifications:**
- Parameters: ~150M
- Model Size: ~600 MB
- Inference: 15ms (CPU), 5ms (GPU)
- Initial Accuracy: 55-60% (with CodeContests)

### 1.3 What We Already Have (Ready to Use)

**Tree-sitter Parsers (COMPLETE):**
- `src-tauri/src/gnn/parser.rs` (278 lines) - Python parser
- `src-tauri/src/gnn/parser_js.rs` (306 lines) - JavaScript/TypeScript parser
- Extracts: functions, classes, imports, calls, inheritance
- Creates: CodeNode and CodeEdge structures
- **Ready for:** Parsing solutions and extracting AST patterns

**CodeContests Dataset (DOWNLOADED):**
- Location: `~/.yantra/datasets/codecontests/`
- Training: 6,508 problems with working solutions
- Validation: 1,627 problems
- Each entry: problem description, solutions, test cases
- **Ready for:** Extracting logic patterns

**GraphSAGE Model (NEEDS RETRAINING):**
- `src-python/model/graphsage.py`
- Current: 978â†’512â†’512â†’256 dimensions
- **Update to:** 978â†’1536â†’1280â†’1024 dimensions
- Issue: Trained on placeholder labels (outputs constant 0.630)
- **Need:** Train on real logic patterns from CodeContests

### 1.4 Implementation Steps

#### Week 1: Extract Logic Patterns from CodeContests

**Goal:** Create training dataset mapping problems â†’ logic patterns (1024-dim embeddings)

**Key Change:** Extract LOGIC patterns, not just AST syntax

```python
# scripts/extract_logic_patterns.py

def extract_logic_pattern(code: str, language: str):
    """Extract logic flow pattern from code"""
    
    # Step 1: Parse with tree-sitter
    tree = parse_code(code, language)
    
    # Step 2: Extract logic flow
    logic_steps = []
    
    def walk_tree(node):
        if node.type == 'if_statement':
            # Classify what kind of check
            logic_steps.append(classify_condition(node))
        elif node.type == 'for_statement':
            logic_steps.append('iteration')
        elif node.type == 'try_statement':
            logic_steps.append('error_handling')
        elif node.type == 'call':
            # Classify API call type
            logic_steps.append(classify_call(node))
        # etc.
        
        for child in node.children:
            walk_tree(child)
    
    walk_tree(tree.root_node)
    
    # Step 3: Convert to 1024-dim embedding
    logic_embedding = encode_logic_pattern(logic_steps)
    
    return logic_embedding

def process_codecontests():
    """Extract logic patterns from all 6,508 solutions"""
    
    train_file = Path.home() / ".yantra/datasets/codecontests/train.jsonl"
    output_file = Path.home() / ".yantra/datasets/logic_patterns.jsonl"
    
    feature_extractor = FeatureExtractor()
    
    with open(train_file) as f, open(output_file, 'w') as out:
        for i, line in enumerate(f):
            if i % 100 == 0:
                print(f"Processed {i} examples...")
            
            example = json.loads(line)
            
            # Extract problem features (978-dim)
            problem_features = feature_extractor.extract_features_from_text(
                example['description']
            )
            
            # Extract logic pattern from solution (1024-dim)
            solution = example['solutions'][0]
            code = solution['solution']
            language = solution['language']
            
            try:
                logic_pattern = extract_logic_pattern(code, language)
                
                training_example = {
                    'problem_id': example.get('name', f'problem_{i}'),
                    'problem_features': problem_features.tolist(),
                    'logic_pattern': logic_pattern.tolist(),
                    'language': language,
                    'complexity': estimate_complexity(code)
                }
                
                out.write(json.dumps(training_example) + '\n')
                
            except Exception as e:
                print(f"Error processing example {i}: {e}")
                continue
```

**Run:**
```bash
.venv/bin/python scripts/extract_logic_patterns.py
```

**Expected Output:**
- `~/.yantra/datasets/logic_patterns.jsonl` with 6,508 entries
- Each entry: problem_features (978-dim) â†’ logic_pattern (1024-dim)

#### Week 2: Train GraphSAGE on Problem â†’ Logic Mapping (1024 dims)

**Goal:** Train GNN to predict logic patterns from problem descriptions

**Update Model Architecture:**
```python
# src-python/model/graphsage.py

class GraphSAGEModel:
    """Updated to 1024 dimensions"""
    
    def __init__(self):
        # 978 â†’ 1536 â†’ 1280 â†’ 1024
        self.gnn_layer1 = SAGEConv(978, 1536, dropout=0.2)
        self.gnn_layer2 = SAGEConv(1536, 1280, dropout=0.2)
        self.gnn_layer3 = SAGEConv(1280, 1024, dropout=0.2)
        
        # Prediction heads
        self.logic_head = nn.Linear(1024, 1024)
        self.confidence_head = nn.Linear(1024, 1)
```

**Training Script:**
```python
# scripts/train_on_logic_patterns.py

def train_graphsage():
    """Train on problem features â†’ logic patterns"""
    
    # Load data
    dataset_file = Path.home() / ".yantra/datasets/logic_patterns.jsonl"
    X_problem, y_logic = load_logic_patterns(dataset_file)
    
    print(f"Dataset: {len(X_problem)} examples")
    print(f"Problem features: {X_problem.shape[1]}-dim")
    print(f"Logic patterns: {y_logic.shape[1]}-dim")
    
    # Create 1024-dim model
    model = GraphSAGEModel(
        input_dim=978,
        hidden_dims=[1536, 1280],
        output_dim=1024,
        dropout=0.2
    )
    
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = torch.nn.MSELoss()
    
    # Split data
    train_size = int(0.8 * len(X_problem))
    X_train, X_val = X_problem[:train_size], X_problem[train_size:]
    y_train, y_val = y_logic[:train_size], y_logic[train_size:]
    
    # Training loop
    best_val_loss = float('inf')
    for epoch in range(100):
        model.train()
        optimizer.zero_grad()
        
        predictions = model(X_train)
        loss = criterion(predictions, y_train)
        
        loss.backward()
        optimizer.step()
        
        # Validation every 10 epochs
        if epoch % 10 == 0:
            model.eval()
            with torch.no_grad():
                val_predictions = model(X_val)
                val_loss = criterion(val_predictions, y_val)
            
            print(f"Epoch {epoch}: train_loss={loss.item():.4f}, val_loss={val_loss.item():.4f}")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save(model.state_dict(), 'models/yantra_codex_v1.pt')
                print(f"âœ… Saved best model (val_loss={val_loss:.4f})")
    
    print("âœ… Training complete!")
```

**Run:**
```bash
.venv/bin/python scripts/train_on_logic_patterns.py
```

**Expected Results:**
- Model achieves <0.1 MSE on validation set
- Can predict logic patterns from problem descriptions
- Initial accuracy: 55-60% on HumanEval

```python
# scripts/extract_ast_patterns.py

import json
from pathlib import Path
import sys
sys.path.append('src-python')
from training.feature_extractor import FeatureExtractor

# Use existing tree-sitter via ctypes or subprocess
import subprocess

def extract_ast_with_treesitter(code: str, language: str):
    """Call Rust parser to extract AST structure"""
    # Option 1: Via temporary file
    temp_file = Path(f"/tmp/temp_code.{language}")
    temp_file.write_text(code)
    
    # Call Rust binary (or create Python bindings)
    # For now, use tree-sitter Python directly
    import tree_sitter_python as tspython
    from tree_sitter import Language, Parser
    
    PY_LANGUAGE = Language(tspython.language())
    parser = Parser(PY_LANGUAGE)
    tree = parser.parse(bytes(code, "utf8"))
    
    # Extract AST patterns
    ast_nodes = []
    ast_edges = []
    
    def walk_tree(node, parent_id=None):
        node_id = f"{node.type}_{node.start_point[0]}"
        ast_nodes.append({
            'id': node_id,
            'type': node.type,
            'start': node.start_point,
            'end': node.end_point,
            'text': code[node.start_byte:node.end_byte][:100]  # truncate
        })
        
        if parent_id:
            ast_edges.append({
                'from': parent_id,
                'to': node_id,
                'type': 'child'
            })
        
        for child in node.children:
            walk_tree(child, node_id)
    
    walk_tree(tree.root_node)
    
    return {
        'nodes': ast_nodes,
        'edges': ast_edges,
        'structure_embedding': compute_structure_embedding(ast_nodes, ast_edges)
    }

def compute_structure_embedding(nodes, edges):
    """Create 256-dim embedding representing AST structure"""
    # Simple approach: Count node types, edge patterns
    from collections import Counter
    
    node_types = Counter(n['type'] for n in nodes)
    edge_patterns = Counter(f"{e['from']}->{e['to']}" for e in edges)
    
    # Convert to fixed-size embedding
    # (In real implementation, use GraphSAGE to generate this)
    embedding = [0.0] * 256
    
    # Encode node type distribution
    for i, (node_type, count) in enumerate(node_types.most_common(50)):
        if i < 128:
            embedding[i] = count / len(nodes)
    
    # Encode edge patterns
    for i, (edge_pattern, count) in enumerate(edge_patterns.most_common(50)):
        if i < 128:
            embedding[128 + i] = count / len(edges)
    
    return embedding

def process_codecontests():
    """Extract AST patterns from all CodeContests solutions"""
    
    train_file = Path.home() / ".yantra/datasets/codecontests/train.jsonl"
    output_file = Path.home() / ".yantra/datasets/ast_patterns.jsonl"
    
    feature_extractor = FeatureExtractor()
    
    with open(train_file) as f, open(output_file, 'w') as out:
        for i, line in enumerate(f):
            if i % 100 == 0:
                print(f"Processed {i} examples...")
            
            example = json.loads(line)
            
            # Extract problem features (978-dim)
            problem_text = example['description']
            problem_features = feature_extractor.extract_features_from_text(problem_text)
            
            # Extract AST from solution
            solution = example['solutions'][0]  # Use first working solution
            code = solution['solution']
            language = solution['language']  # Usually Python
            
            try:
                ast_data = extract_ast_with_treesitter(code, language)
                
                # Create training example
                training_example = {
                    'problem_id': example.get('name', f'problem_{i}'),
                    'problem_features': problem_features.tolist(),
                    'ast_structure': ast_data['structure_embedding'],
                    'ast_nodes': len(ast_data['nodes']),
                    'ast_edges': len(ast_data['edges']),
                    'language': language,
                    'code_length': len(code)
                }
                
                out.write(json.dumps(training_example) + '\n')
                
            except Exception as e:
                print(f"Error processing example {i}: {e}")
                continue
    
    print(f"âœ… Extracted AST patterns from CodeContests")
    print(f"ğŸ“ Output: {output_file}")

if __name__ == '__main__':
    process_codecontests()
```

**Run:**
```bash
cd /Users/vivekdurairaj/Projects/yantra
.venv/bin/python scripts/extract_ast_patterns.py
```

**Expected Output:**
- `~/.yantra/datasets/ast_patterns.jsonl` with 6,508 entries
- Each entry: problem_features (978-dim) â†’ ast_structure (256-dim)

#### Week 2: Train GraphSAGE on Problem â†’ AST Mapping

**Goal:** Train GNN to predict AST structure from problem features

```python
# scripts/train_on_ast_patterns.py

import torch
import json
from pathlib import Path
import sys
sys.path.append('src-python')

from model.graphsage import GraphSAGEModel
from torch_geometric.data import Data, DataLoader

def load_ast_patterns():
    """Load training data"""
    dataset_file = Path.home() / ".yantra/datasets/ast_patterns.jsonl"
    
    problem_features = []
    ast_embeddings = []
    
    with open(dataset_file) as f:
        for line in f:
            example = json.loads(line)
            problem_features.append(example['problem_features'])
            ast_embeddings.append(example['ast_structure'])
    
    return torch.tensor(problem_features), torch.tensor(ast_embeddings)

def train_graphsage():
    """Train GraphSAGE on problem â†’ AST mapping"""
    
    print("Loading AST patterns...")
    X_problem, y_ast = load_ast_patterns()
    
    print(f"Dataset size: {len(X_problem)} examples")
    print(f"Problem features: {X_problem.shape[1]}-dim")
    print(f"AST embeddings: {y_ast.shape[1]}-dim")
    
    # Create model
    model = GraphSAGEModel(
        input_dim=978,  # Problem features
        hidden_dims=[512, 512],
        output_dim=256,  # AST embedding
        num_classes=256,
        dropout=0.3
    )
    
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = torch.nn.MSELoss()  # Predict AST embedding
    
    # Split data
    train_size = int(0.8 * len(X_problem))
    X_train, X_val = X_problem[:train_size], X_problem[train_size:]
    y_train, y_val = y_ast[:train_size], y_ast[train_size:]
    
    print(f"Training on {train_size} examples...")
    
    # Training loop
    best_val_loss = float('inf')
    for epoch in range(100):
        model.train()
        optimizer.zero_grad()
        
        # Forward pass (simplified - actual GraphSAGE needs graph structure)
        # For now, treat as regression problem
        predictions = model.code_embedding_head(model.gnn_layer3(X_train))
        loss = criterion(predictions, y_train)
        
        loss.backward()
        optimizer.step()
        
        # Validation
        if epoch % 10 == 0:
            model.eval()
            with torch.no_grad():
                val_predictions = model.code_embedding_head(model.gnn_layer3(X_val))
                val_loss = criterion(val_predictions, y_val)
            
            print(f"Epoch {epoch}: train_loss={loss.item():.4f}, val_loss={val_loss.item():.4f}")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                # Save model
                torch.save(model.state_dict(), 'models/graphsage_ast_predictor.pt')
                print(f"âœ… Saved best model (val_loss={val_loss:.4f})")
    
    print("âœ… Training complete!")
    print(f"ğŸ“ Model saved: models/graphsage_ast_predictor.pt")

if __name__ == '__main__':
    train_graphsage()
```

**Run:**
```bash
.venv/bin/python scripts/train_on_ast_patterns.py
```

**Expected Results:**
- Model achieves <0.1 MSE on validation set
- Can predict AST structure embeddings from problem descriptions

#### Week 3: Implement Code Generation Pipeline

**Goal:** Problem â†’ GNN Logic Pattern â†’ Tree-sitter Code

```rust
// src-tauri/src/codex/generator.rs

use crate::gnn::parser::{CodeNode, CodeEdge};
use std::process::Command;
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct LogicPattern {
    pub steps: Vec<LogicStep>,
    pub confidence: f32,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum LogicStep {
    NullCheck { variable: String },
    ValidationCheck { pattern: String },
    DatabaseQuery { operation: String },
    Iteration { collection: String },
    ErrorHandling { error_type: String },
    ApiCall { api: String, method: String },
}

pub struct CodeGenerator {
    model_path: String,
}

impl CodeGenerator {
    pub fn new(model_path: String) -> Self {
        Self { model_path }
    }
    
    pub fn generate_code(&self, problem: &str, language: &str) -> Result<(String, f32), Box<dyn std::error::Error>> {
        // Step 1: Extract problem features (978-dim)
        let features = self.extract_problem_features(problem)?;
        
        // Step 2: GNN predicts universal logic pattern (1024-dim)
        let logic_embedding = self.predict_logic_pattern(&features)?;
        
        // Step 3: Decode embedding to logic steps
        let logic_pattern = self.decode_logic_pattern(&logic_embedding)?;
        
        // Step 4: Tree-sitter generates language-specific code
        let code = self.generate_from_logic(&logic_pattern, language)?;
        
        Ok((code, logic_pattern.confidence))
    }
    
    fn extract_problem_features(&self, problem: &str) -> Result<Vec<f32>, Box<dyn std::error::Error>> {
        // Call Python feature extractor
        let output = Command::new("python3")
            .args(&[
                "src-python/training/feature_extractor.py",
                "--text", problem
            ])
            .output()?;
        
        let features: Vec<f32> = serde_json::from_slice(&output.stdout)?;
        Ok(features)
    }
    
    fn predict_ast_structure(&self, features: &[f32]) -> Result<Vec<f32>, Box<dyn std::error::Error>> {
        // Call Python model inference
        let output = Command::new("python3")
            .args(&[
                "-c",
                &format!(r#"
import torch
import sys
sys.path.append('src-python')
from model.graphsage import GraphSAGEModel

model = GraphSAGEModel(978, [512, 512], 256, 256)
model.load_state_dict(torch.load('{}'))
model.eval()

features = torch.tensor({:?})
with torch.no_grad():
    embedding = model.code_embedding_head(model.gnn_layer3(features))
    print(embedding.tolist())
"#, self.model_path, features)
            ])
            .output()?;
        
        let embedding: Vec<f32> = serde_json::from_slice(&output.stdout)?;
        Ok(embedding)
    }
    
    fn embedding_to_ast(&self, embedding: &[f32]) -> Result<Vec<CodeNode>, Box<dyn std::error::Error>> {
        // Decode embedding into AST node sequence
        // This is the inverse of compute_structure_embedding()
        
        // For MVP: Use template-based approach
        // Later: Train decoder network
        
        let mut nodes = Vec::new();
        
        // Analyze embedding to determine structure
        let has_function = embedding[0] > 0.5;
        let has_class = embedding[1] > 0.5;
        let has_loop = embedding[10] > 0.5;
        
        if has_function {
            nodes.push(CodeNode {
                id: "func_main".to_string(),
                node_type: "function".to_string(),
                name: Some("solve".to_string()),
                file_path: "generated.py".to_string(),
                line_start: 1,
                line_end: 10,
            });
        }
        
        // TODO: More sophisticated decoding
        
        Ok(nodes)
    }
    
    fn ast_to_code(&self, nodes: &[CodeNode]) -> Result<String, Box<dyn std::error::Error>> {
        // Use tree-sitter to generate code from AST
        
        // For MVP: Template-based generation
        let mut code = String::new();
        
        for node in nodes {
            match node.node_type.as_str() {
                "function" => {
                    code.push_str(&format!("def {}():\n", node.name.as_ref().unwrap()));
                    code.push_str("    pass\n");
                }
                "class" => {
                    code.push_str(&format!("class {}:\n", node.name.as_ref().unwrap()));
                    code.push_str("    pass\n");
                }
                _ => {}
            }
        }
        
        Ok(code)
    }
}
```

#### Week 4: Build On-the-Go Learning System

**Goal:** Learn from every generation without separate training phase

```python
# src-python/learning/online_learner.py

import torch
import json
from pathlib import Path
from collections import deque
from datetime import datetime

class OnlineLearner:
    """
    Learns from every code generation in real-time.
    No separate training phase needed.
    """
    
    def __init__(self, model, learning_rate=0.0001):
        self.model = model
        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
        self.criterion = torch.nn.MSELoss()
        
        # Experience replay buffer (store last 1000 examples)
        self.replay_buffer = deque(maxlen=1000)
        
        # Adaptive threshold
        self.confidence_threshold = 0.7
        self.recent_successes = deque(maxlen=100)
        
        # Stats
        self.total_generations = 0
        self.gnn_successes = 0
        self.llm_fallbacks = 0
    
    def generate_with_learning(self, problem):
        """
        Generate code and learn from the result.
        Returns: (code, used_llm, test_passed)
        """
        
        # Step 1: Try GNN first
        gnn_prediction, confidence = self.model.predict(problem)
        
        if confidence >= self.confidence_threshold:
            # Use GNN prediction
            code = self.gnn_to_code(gnn_prediction)
            used_llm = False
        else:
            # Fallback to LLM
            code = self.call_llm(problem)
            used_llm = True
        
        # Step 2: Execute tests
        test_passed = self.run_tests(code)
        
        # Step 3: Learn from result
        self.learn_from_generation(problem, code, test_passed, used_llm)
        
        # Step 4: Update stats and threshold
        self.update_stats(test_passed, used_llm)
        self.adapt_threshold()
        
        return code, used_llm, test_passed
    
    def learn_from_generation(self, problem, code, test_passed, used_llm):
        """Learn from this generation"""
        
        # Extract features
        problem_features = self.extract_features(problem)
        ast_embedding = self.extract_ast(code)
        
        # Add to replay buffer
        example = {
            'problem_features': problem_features,
            'ast_embedding': ast_embedding,
            'test_passed': test_passed,
            'used_llm': used_llm,
            'timestamp': datetime.now().isoformat()
        }
        self.replay_buffer.append(example)
        
        # Immediate learning (if test passed)
        if test_passed:
            self.train_on_example(problem_features, ast_embedding)
        
        # Batch learning every 50 examples
        if len(self.replay_buffer) >= 50 and self.total_generations % 50 == 0:
            self.train_on_replay_buffer()
    
    def train_on_example(self, problem_features, ast_embedding):
        """Single gradient update"""
        self.model.train()
        self.optimizer.zero_grad()
        
        prediction = self.model(problem_features)
        loss = self.criterion(prediction, ast_embedding)
        
        loss.backward()
        self.optimizer.step()
    
    def train_on_replay_buffer(self):
        """Batch learning from experience replay"""
        # Sample 32 random examples
        import random
        batch = random.sample(list(self.replay_buffer), min(32, len(self.replay_buffer)))
        
        # Only train on successful examples
        successful = [ex for ex in batch if ex['test_passed']]
        
        if len(successful) == 0:
            return
        
        self.model.train()
        self.optimizer.zero_grad()
        
        total_loss = 0
        for ex in successful:
            prediction = self.model(ex['problem_features'])
            loss = self.criterion(prediction, ex['ast_embedding'])
            total_loss += loss
        
        total_loss.backward()
        self.optimizer.step()
        
        print(f"ğŸ“š Replay learning: {len(successful)} examples, loss={total_loss.item():.4f}")
    
    def adapt_threshold(self):
        """Adjust confidence threshold based on recent performance"""
        if len(self.recent_successes) < 20:
            return
        
        success_rate = sum(self.recent_successes) / len(self.recent_successes)
        
        # If doing well, increase threshold (be more confident)
        if success_rate > 0.9:
            self.confidence_threshold = min(0.9, self.confidence_threshold + 0.05)
        # If doing poorly, decrease threshold (use LLM more)
        elif success_rate < 0.7:
            self.confidence_threshold = max(0.5, self.confidence_threshold - 0.05)
        
        print(f"ğŸ¯ Adjusted threshold to {self.confidence_threshold:.2f} (success_rate={success_rate:.2f})")
    
    def update_stats(self, test_passed, used_llm):
        """Track statistics"""
        self.total_generations += 1
        self.recent_successes.append(test_passed)
        
        if not used_llm and test_passed:
            self.gnn_successes += 1
        elif used_llm:
            self.llm_fallbacks += 1
        
        if self.total_generations % 100 == 0:
            self.print_stats()
    
    def print_stats(self):
        """Print learning progress"""
        gnn_accuracy = self.gnn_successes / self.total_generations if self.total_generations > 0 else 0
        llm_usage = self.llm_fallbacks / self.total_generations if self.total_generations > 0 else 0
        
        print(f"""
        ğŸ“Š Learning Stats (after {self.total_generations} generations):
        - GNN Accuracy: {gnn_accuracy:.1%}
        - LLM Usage: {llm_usage:.1%}
        - Confidence Threshold: {self.confidence_threshold:.2f}
        - Replay Buffer: {len(self.replay_buffer)} examples
        """)
```

**Expected Progression:**
```
Generation 1-100:
- GNN accuracy: 40%
- LLM usage: 60%

Generation 100-500:
- GNN accuracy: 60%
- LLM usage: 40%

Generation 500-1000:
- GNN accuracy: 85%
- LLM usage: 15%

Generation 1000+:
- GNN accuracy: 95%
- LLM usage: 5%
```

---

## Part 2: Yantra Cloud Codex (Universal Collective Intelligence)

### 2.1 Architecture Overview

**Privacy-Preserving Universal Learning:**

```
Local User A (Python)           Local User B (JavaScript)
    â”‚                                â”‚
    â”‚ Generate code                  â”‚ Generate code
    â”‚ Tests pass âœ…                 â”‚ Tests pass âœ…
    â”‚                                â”‚
    â”‚ Extract logic pattern           â”‚ Extract logic pattern
    â”‚ (embeddings only, no code)      â”‚ (embeddings only, no code)
    â”‚                                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         Yantra Cloud Codex
         (Universal Model)
         Learn from ALL users
                 â”‚
                 â–¼
         Retrain Central GNN
         (1024-dim embeddings)
                 â”‚
                 â–¼
         Push model updates
         (Weekly or threshold-based)
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                â–¼
    Update A's GNN    Update B's GNN
    (Both benefit!)   (Both benefit!)
    
    JavaScript patterns â†’ Help Python users!
    Python patterns â†’ Help JavaScript users!
```

**Key Difference from Traditional Approaches:**
- âŒ NOT per-user personalization (each user's own model)
- âœ… Universal collective intelligence (one model for all)
- Pattern learned in Python automatically helps JavaScript
- Network effects: More users = Better for everyone

### 2.2 What Gets Sent to Cloud

**ONLY anonymous logic pattern embeddings (NOT code!):**
```json
{
  "user_id": "anonymous_hash_abc123",
  "logic_embedding": [0.234, -0.567, 0.891, ...],  // 1024-dim vector
  "logic_steps": ["null_check", "validation", "db_insert", "error_handle"],
  "test_passed": true,
  "source_language": "python",
  "problem_features": [0.123, ...],  // 978-dim
  "complexity": 3,
  "timestamp": "2025-11-26T10:00:00Z"
}
```

**NEVER sent:**
- Actual code
- Problem descriptions
- File names or paths
- Project structure
- Any identifiable information

### 2.3 Knowledge Distillation (LLM â†’ GNN)

**When user uses LLM:**
```python
# User's machine
1. User requests code generation
2. GNN confidence < 0.7 â†’ Use LLM
3. LLM generates code
4. Tests execute â†’ Code passes âœ…
5. Extract AST pattern from working code
6. Train local GNN on this pattern
7. Send anonymous pattern embedding to cloud
```

**Cloud processing:**
```python
# Yantra Cloud
1. Receive pattern embeddings from all users
2. Aggregate patterns by type
3. Identify common successful patterns
4. Train central GraphSAGE model
5. Validate on held-out test set
6. Package improved model
7. Push to all users (monthly updates)
```

### 2.4 Network Effects

**The Flywheel:**

```
User A uses GPT-4 ($0.02/generation)
    â†’ Generates working code
    â†’ Pattern learned by User A's GNN
    â†’ Pattern sent to cloud (anonymous)
    â†’ Central GNN learns pattern
    â†’ Update pushed to ALL users
    â†’ User B (FREE tier) gets this knowledge
    â†’ User B's GNN can now solve similar problems
    â†’ User B doesn't need LLM for this pattern
    â†’ Cost savings: $0.02 â†’ $0.0001
```

**After 10,000 users Ã— 1,000 generations each:**
- 10 million validated code patterns
- Central GNN knows: common APIs, design patterns, testing strategies
- ALL users benefit from collective intelligence
- Free users get near-GPT-4 quality without paying

### 2.5 Implementation (Month 3-6)

**Cloud Infrastructure:**

```python
# Yantra Cloud API
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class PatternSubmission(BaseModel):
    user_id: str  # Anonymous hash
    pattern_embedding: list[float]
    pattern_type: str
    test_passed: bool
    language: str

@app.post("/api/v1/submit-pattern")
async def submit_pattern(submission: PatternSubmission):
    """Receive pattern from user"""
    
    # Store in pattern database
    await db.patterns.insert({
        'user_id': submission.user_id,
        'embedding': submission.pattern_embedding,
        'type': submission.pattern_type,
        'passed': submission.test_passed,
        'language': submission.language,
        'timestamp': datetime.now()
    })
    
    return {"status": "received"}

@app.get("/api/v1/model-update")
async def get_model_update(current_version: str):
    """Check for model updates"""
    
    latest_version = await db.models.find_one(sort=[('version', -1)])
    
    if latest_version['version'] > current_version:
        return {
            "update_available": True,
            "version": latest_version['version'],
            "download_url": latest_version['url'],
            "changelog": latest_version['changelog']
        }
    
    return {"update_available": False}
```

**Federated Training:**

```python
# Cloud training job (runs weekly)
import torch
from pymongo import MongoClient

def train_central_model():
    """Train on aggregated patterns from all users"""
    
    # Load patterns from last week
    patterns = db.patterns.find({
        'timestamp': {'$gte': datetime.now() - timedelta(days=7)},
        'test_passed': True  # Only successful patterns
    })
    
    # Aggregate by pattern type
    pattern_groups = {}
    for p in patterns:
        pattern_type = p['pattern_type']
        if pattern_type not in pattern_groups:
            pattern_groups[pattern_type] = []
        pattern_groups[pattern_type].append(p['embedding'])
    
    # Train central GNN
    model = CentralGraphSAGE()
    
    for pattern_type, embeddings in pattern_groups.items():
        X = torch.tensor(embeddings)
        # Self-supervised learning: Predict embedding from noisy version
        model.train_on_patterns(X, pattern_type)
    
    # Save new model version
    version = get_next_version()
    torch.save(model.state_dict(), f'models/central_v{version}.pt')
    
    # Update database
    db.models.insert({
        'version': version,
        'url': f'https://cdn.yantra.ai/models/v{version}.pt',
        'created': datetime.now(),
        'num_patterns': len(patterns),
        'changelog': f'Trained on {len(patterns)} new patterns'
    })
    
    print(f"âœ… New model v{version} ready for distribution")
```

---

## Timeline & Milestones

### Month 1-2: Local GNN (Phase 1)

**Week 1:** Extract AST patterns from CodeContests
- âœ… Script to parse 6,508 solutions with tree-sitter
- âœ… Generate problem_features â†’ ast_structure dataset

**Week 2:** Train GraphSAGE on real data
- âœ… Train on problem â†’ AST mapping
- âœ… Achieve 60% validation accuracy
- âœ… Save model for inference

**Week 3:** Code generation pipeline
- âœ… GNN predicts AST embeddings
- âœ… Decode embeddings to AST nodes
- âœ… Tree-sitter generates code text
- âœ… Integrate with Yantra UI

**Week 4:** On-the-go learning
- âœ… Experience replay buffer
- âœ… Adaptive confidence threshold
- âœ… Learn from every generation
- âœ… Track improvement metrics

**Month 2 Target:**
- GNN accuracy: 60% on day 1 â†’ 85% after 1000 generations
- LLM usage: 100% â†’ 15%
- Speed: 3s per generation (vs 30s with LLM)
- Cost: $0.0001 per generation (vs $0.02 with LLM)

### Month 3-4: Cloud Infrastructure (Phase 2)

**Week 5-6:** Cloud API setup
- âœ… Pattern submission endpoint
- âœ… Model update distribution
- âœ… Privacy-preserving storage
- âœ… User authentication (anonymous)

**Week 7-8:** Federated learning
- âœ… Pattern aggregation pipeline
- âœ… Central GNN training
- âœ… Model versioning & distribution
- âœ… Automatic update checks

**Month 4 Target:**
- 100 beta users submitting patterns
- 10,000+ validated patterns in database
- First model update pushed successfully

### Month 5-6: Scale & Optimize

**Week 9-10:** Performance optimization
- âœ… Compress pattern embeddings
- âœ… Incremental model updates
- âœ… CDN for model distribution
- âœ… Background sync for users

**Week 11-12:** Quality improvements
- âœ… Pattern quality scoring
- âœ… Detect and filter noisy patterns
- âœ… A/B test model versions
- âœ… User feedback loop

**Month 6 Target:**
- 1,000+ active users
- 100,000+ validated patterns
- GNN accuracy: 90%+ (better than GPT-3.5)
- LLM usage: <5% for most users

---

## Success Metrics

### Phase 1 (Local GNN)

**Week 1:**
- GNN accuracy: 40% (bootstrap from CodeContests)
- LLM usage: 60%

**Week 4:**
- GNN accuracy: 60%
- LLM usage: 40%

**Month 2:**
- GNN accuracy: 85%
- LLM usage: 15%
- User satisfaction: NPS >50

### Phase 2 (Cloud Collective)

**Month 4:**
- 100 users submitting patterns
- 10,000 validated patterns
- First successful model update

**Month 6:**
- 1,000 users
- 100,000 patterns
- GNN accuracy: 90%
- LLM usage: <5%

**Month 12:**
- 10,000 users
- 1,000,000 patterns
- GNN accuracy: 95% (matches GPT-4)
- LLM usage: <2%
- Cost savings: $30/month â†’ $0.50/month

---

## Technical FAQ

### Q: How does GNN generate code if it outputs numbers?

**A:** GNN predicts AST structure (embeddings), tree-sitter converts AST to code text.

```
GNN: [0.89, -0.23, ...] â†’ "This looks like a function with a for loop"
Decoder: Embeddings â†’ AST nodes (function, for_loop, return)
Tree-sitter: AST nodes â†’ "def solve():\n    for i in range(n):\n        ..."
```

### Q: What if user doesn't want to share patterns?

**A:** Completely optional. Users can disable cloud sync in settings. They'll still benefit from on-the-go local learning, just won't contribute to or receive collective improvements.

### Q: How is privacy preserved?

**A:** Only anonymous pattern embeddings sent, never code. Embeddings are 256-dimensional vectors with no reverse mapping to original code. User IDs are hashed. No PII collected.

### Q: Why not just use LLM for everything?

**A:** 
- Cost: $0.02 vs $0.0001 per generation (200x cheaper)
- Speed: 3s vs 30s (10x faster)
- Privacy: Local inference, no API calls
- Offline: Works without internet
- Learning: Improves over time, LLM doesn't

### Q: When will GNN be better than GPT-4?

**A:** 
- Month 2: Better than GPT-3.5 (60% â†’ 85% accuracy)
- Month 6: Comparable to GPT-4 for common patterns (90% accuracy)
- Month 12: Better than GPT-4 for specific domains (95% accuracy on user's codebase)

### Q: What about new programming languages?

**A:** Tree-sitter supports 40+ languages. We can add new language parsers incrementally. GNN learns patterns that transfer across languages (e.g., "API call with retry" pattern works in Python, JavaScript, Rust).

---

## Next Steps (Immediate Actions)

### This Week:

1. **[CRITICAL]** Implement `scripts/extract_ast_patterns.py`
   - Parse all 6,508 CodeContests solutions
   - Extract AST structures with tree-sitter
   - Generate problem â†’ AST training dataset

2. **[HIGH]** Update GraphSAGE training script
   - Load AST patterns dataset
   - Train on problem features â†’ AST embeddings
   - Save trained model

3. **[HIGH]** Create code generation pipeline
   - Rust wrapper for GNN inference
   - AST decoder (embeddings â†’ nodes)
   - Tree-sitter code generation

4. **[MEDIUM]** Build on-the-go learning system
   - Experience replay buffer
   - Adaptive threshold adjustment
   - Stats tracking

### Next Month:

5. **[MEDIUM]** Cloud API infrastructure
6. **[LOW]** Federated learning pipeline
7. **[LOW]** Model update distribution

---

## Conclusion

**Yantra Codex represents a fundamental shift:**

From: "AI-assisted coding" (human writes, AI suggests)
To: "AI-primary coding" (AI writes, human validates, AI learns)

**The Innovation:**

1. **Local GNN** learns from your code style
2. **Tree-sitter** ensures syntactic correctness
3. **On-the-go learning** improves with every generation
4. **Cloud collective** shares knowledge across all users
5. **Privacy-preserving** - no code leaves your machine

**The Result:**

- 200x cheaper than LLM ($0.0001 vs $0.02)
- 10x faster than LLM (3s vs 30s)
- Works offline
- Improves continuously
- Eventually surpasses GPT-4 for specific domains

**The Vision:**

Within 12 months, Yantra users will have a personalized AI that:
- Knows their codebase better than GPT-4
- Generates code faster than any LLM
- Costs nothing after initial learning
- Improves with every use
- Benefits from collective intelligence of all users

---

**Status:** Ready to implement. All components identified. Tree-sitter ready. Dataset ready. Let's build! ğŸš€
